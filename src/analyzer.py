"""
Module d'analyse IA - Sentiment analysis et statistiques avanc√©es
"""

"""
Module d'analyse IA - Sentiment analysis et statistiques avanc√©es
"""

import pandas as pd
import numpy as np
from transformers import pipeline
from tqdm import tqdm
import warnings
import sys
import os

# Ajouter les dossiers au path Python
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)
sys.path.insert(0, current_dir)

from src.logger import get_logger

# D√©sactiver les warnings de transformers (pour un affichage propre)
warnings.filterwarnings('ignore')

logger = get_logger(__name__)


class ProductAnalyzer:
    """
    Classe pour analyser les produits avec IA
    """
    
    def __init__(self):
        """
        Initialise l'analyseur avec un mod√®le de sentiment
        """
        logger.info("ü§ñ Initialisation du mod√®le d'analyse de sentiment...")
        
        try:
            # Charge un mod√®le pr√©-entra√Æn√© pour l'analyse de sentiment
            self.sentiment_analyzer = pipeline(
                "sentiment-analysis",
                model="distilbert-base-uncased-finetuned-sst-2-english",
                device=-1  # -1 = CPU, 0 = GPU
            )
            logger.info("‚úÖ Mod√®le charg√© avec succ√®s")
        except Exception as e:
            logger.error(f"‚ùå Erreur lors du chargement du mod√®le : {e}")
            self.sentiment_analyzer = None
    
    
    def analyze_sentiment(self, text):
        """
        Analyse le sentiment d'un texte
        
        Args:
            text (str): Texte √† analyser
            
        Returns:
            dict: {'label': 'POSITIVE'/'NEGATIVE', 'score': 0.95}
        """
        if not self.sentiment_analyzer:
            return {'label': 'UNKNOWN', 'score': 0.0}
        
        try:
            # Limite √† 512 caract√®res (limite du mod√®le)
            text = str(text)[:512]
            result = self.sentiment_analyzer(text)[0]
            return result
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è  Erreur d'analyse pour '{text[:30]}...': {e}")
            return {'label': 'UNKNOWN', 'score': 0.0}
    
    
    def analyze_products_dataframe(self, df):
        """
        Analyse tous les produits d'un DataFrame
        
        Args:
            df (pd.DataFrame): DataFrame avec les produits
            
        Returns:
            pd.DataFrame: DataFrame enrichi avec analyse de sentiment
        """
        logger.info(f"üîç Analyse de sentiment sur {len(df)} produits...")
        
        if self.sentiment_analyzer is None:
            logger.error("‚ùå Mod√®le non disponible, analyse annul√©e")
            return df
        
        # Copie pour ne pas modifier l'original
        df_analyzed = df.copy()
        
        # Listes pour stocker les r√©sultats
        sentiments = []
        scores = []
        
        # Barre de progression
        for idx, row in tqdm(df_analyzed.iterrows(), total=len(df_analyzed), desc="Analyse IA"):
            result = self.analyze_sentiment(row['title'])
            sentiments.append(result['label'])
            scores.append(result['score'])
        
        # Ajouter les colonnes au DataFrame
        df_analyzed['sentiment'] = sentiments
        df_analyzed['sentiment_score'] = scores
        
        logger.info("‚úÖ Analyse de sentiment termin√©e")
        
        return df_analyzed
    
    
    def compute_statistics(self, df):
        """
        Calcule des statistiques avanc√©es
        
        Args:
            df (pd.DataFrame): DataFrame analys√©
            
        Returns:
            dict: Statistiques calcul√©es
        """
        logger.info("üìä Calcul des statistiques...")
        
        stats = {
            'total_products': len(df),
            'avg_price': df['price'].mean(),
            'median_price': df['price'].median(),
            'min_price': df['price'].min(),
            'max_price': df['price'].max(),
            'std_price': df['price'].std(),
        }
        
        # Statistiques par cat√©gorie
        if 'category' in df.columns:
            stats['categories'] = df['category'].value_counts().to_dict()
            stats['avg_price_by_category'] = df.groupby('category')['price'].mean().to_dict()
        
        # Statistiques de sentiment
        if 'sentiment' in df.columns:
            stats['sentiment_distribution'] = df['sentiment'].value_counts().to_dict()
            stats['avg_sentiment_score'] = df['sentiment_score'].mean()
            
            # Sentiment par cat√©gorie
            sentiment_by_cat = df.groupby('category')['sentiment'].value_counts().unstack(fill_value=0)
            stats['sentiment_by_category'] = sentiment_by_cat.to_dict()
        
        logger.info("‚úÖ Statistiques calcul√©es")
        
        return stats
    
    
    def generate_insights(self, df, stats):
        """
        G√©n√®re des insights business √† partir des donn√©es
        
        Args:
            df (pd.DataFrame): DataFrame analys√©
            stats (dict): Statistiques calcul√©es
            
        Returns:
            list: Liste d'insights
        """
        logger.info("üí° G√©n√©ration d'insights...")
        
        insights = []
        
        # Insight 1 : Prix
        if stats['avg_price'] > stats['median_price']:
            insights.append(
                f"‚ö†Ô∏è  Le prix moyen (${stats['avg_price']:.2f}) est sup√©rieur au prix m√©dian "
                f"(${stats['median_price']:.2f}), indiquant quelques produits tr√®s chers."
            )
        
        # Insight 2 : Cat√©gorie dominante
        if 'categories' in stats:
            top_category = max(stats['categories'].items(), key=lambda x: x[1])
            insights.append(
                f"üì¶ Cat√©gorie dominante : '{top_category[0]}' avec {top_category[1]} produits "
                f"({(top_category[1]/stats['total_products']*100):.1f}%)"
            )
        
        # Insight 3 : Sentiment
        if 'sentiment_distribution' in stats:
            positive_pct = stats['sentiment_distribution'].get('POSITIVE', 0) / stats['total_products'] * 100
            negative_pct = stats['sentiment_distribution'].get('NEGATIVE', 0) / stats['total_products'] * 100
            
            if positive_pct > 70:
                insights.append(
                    f"üòä Excellent ! {positive_pct:.1f}% des produits ont un titre positif"
                )
            elif negative_pct > 30:
                insights.append(
                    f"‚ö†Ô∏è  Attention : {negative_pct:.1f}% des produits ont un titre n√©gatif"
                )
        
        # Insight 4 : Produit le plus cher
        most_expensive = df.loc[df['price'].idxmax()]
        insights.append(
            f"üí∞ Produit le plus cher : '{most_expensive['title'][:50]}...' √† ${most_expensive['price']:.2f}"
        )
        
        # Insight 5 : Produit le moins cher
        cheapest = df.loc[df['price'].idxmin()]
        insights.append(
            f"üíµ Produit le moins cher : '{cheapest['title'][:50]}...' √† ${cheapest['price']:.2f}"
        )
        
        logger.info(f"‚úÖ {len(insights)} insights g√©n√©r√©s")
        
        return insights


def analyze_products(input_file, output_file, config):
    """
    Fonction principale d'analyse
    
    Args:
        input_file (str): Fichier CSV √† analyser
        output_file (str): Fichier de sortie
        config (dict): Configuration
        
    Returns:
        tuple: (DataFrame analys√©, statistiques, insights)
    """
    logger.info("=" * 60)
    logger.info("ü§ñ D√âMARRAGE DE L'ANALYSE IA")
    logger.info("=" * 60)
    
    # Charger les donn√©es
    logger.info(f"üìÇ Chargement depuis {input_file}...")
    df = pd.read_csv(input_file, encoding='utf-8')
    logger.info(f"‚úÖ {len(df)} produits charg√©s")
    
    # Initialiser l'analyseur
    analyzer = ProductAnalyzer()
    
    # Analyser le sentiment
    df_analyzed = analyzer.analyze_products_dataframe(df)
    
    # Calculer les statistiques
    stats = analyzer.compute_statistics(df_analyzed)
    
    # G√©n√©rer les insights
    insights = analyzer.generate_insights(df_analyzed, stats)
    
    # Afficher les insights
    logger.info("\n" + "=" * 60)
    logger.info("üí° INSIGHTS BUSINESS")
    logger.info("=" * 60)
    for insight in insights:
        logger.info(insight)
    logger.info("=" * 60 + "\n")
    
    # Sauvegarder
    df_analyzed.to_csv(output_file, index=False, encoding='utf-8')
    logger.info(f"‚úÖ R√©sultats sauvegard√©s : {output_file}")
    
    return df_analyzed, stats, insights


# Point d'entr√©e si ex√©cut√© directement
if __name__ == "__main__":
    from src.logger import load_config
    
    config = load_config()
    
    # Analyser le dernier fichier nettoy√©
    import glob
    import os
    
    processed_files = glob.glob(f"{config['paths']['processed_data']}/products_clean_*.csv")
    
    if processed_files:
        latest_file = max(processed_files, key=os.path.getctime)
        output_file = latest_file.replace('_clean_', '_analyzed_')
        
        analyze_products(latest_file, output_file, config)
    else:
        logger.error("‚ùå Aucun fichier nettoy√© trouv√©")