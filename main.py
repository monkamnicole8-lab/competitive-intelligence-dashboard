"""
Pipeline principal - Orchestre toutes les Ã©tapes du projet
Version finale avec dashboard Excel automatique
"""

import sys
import os
from datetime import datetime

sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.logger import get_logger, load_config
from src.scraper import run_scraper
from src.cleaner import load_raw_data, inspect_data, clean_data, save_clean_data
from src.analyzer import analyze_products
from src.visualizer import create_dashboard

logger = get_logger(__name__)


def run_full_pipeline():
    """
    ExÃ©cute le pipeline complet : collecte â†’ nettoyage â†’ analyse â†’ dashboard
    """
    logger.info("\n" + "=" * 70)
    logger.info("ğŸš€ DÃ‰MARRAGE DU PIPELINE COMPLET - VEILLE CONCURRENTIELLE")
    logger.info("=" * 70)
    
    start_time = datetime.now()
    logger.info(f"â° Heure de dÃ©marrage : {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # Charger la configuration
    config = load_config()
    logger.info("âœ… Configuration chargÃ©e")
    
    # Variables pour stocker les chemins de fichiers
    files_created = {
        'raw': None,
        'clean': None,
        'analyzed': None,
        'dashboard': None
    }
    
    try:
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 1 : COLLECTE DES DONNÃ‰ES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.info("\n" + "â”€" * 70)
        logger.info("ğŸ“¡ Ã‰TAPE 1/4 : COLLECTE DES DONNÃ‰ES")
        logger.info("â”€" * 70)
        
        raw_file = run_scraper(config)
        
        if not raw_file:
            logger.error("âŒ Ã‰chec de la collecte - ArrÃªt du pipeline")
            return False, files_created
        
        files_created['raw'] = raw_file
        logger.info(f"âœ… Collecte terminÃ©e : {raw_file}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 2 : NETTOYAGE DES DONNÃ‰ES
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.info("\n" + "â”€" * 70)
        logger.info("ğŸ§¹ Ã‰TAPE 2/4 : NETTOYAGE DES DONNÃ‰ES")
        logger.info("â”€" * 70)
        
        df_raw = load_raw_data(raw_file)
        
        if df_raw is None:
            logger.error("âŒ Impossible de charger les donnÃ©es - ArrÃªt du pipeline")
            return False, files_created
        
        logger.info("\nğŸ“Š Inspection des donnÃ©es brutes :")
        inspect_data(df_raw)
        
        df_clean = clean_data(df_raw)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        clean_file = f"{config['paths']['processed_data']}/products_clean_{timestamp}.csv"
        save_clean_data(df_clean, clean_file)
        
        files_created['clean'] = clean_file
        logger.info(f"âœ… Nettoyage terminÃ© : {clean_file}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 3 : ANALYSE IA
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.info("\n" + "â”€" * 70)
        logger.info("ğŸ¤– Ã‰TAPE 3/4 : ANALYSE IA ET INSIGHTS")
        logger.info("â”€" * 70)
        
        analyzed_file = clean_file.replace('_clean_', '_analyzed_')
        df_analyzed, stats, insights = analyze_products(clean_file, analyzed_file, config)
        
        files_created['analyzed'] = analyzed_file
        logger.info(f"âœ… Analyse terminÃ©e : {analyzed_file}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Ã‰TAPE 4 : GÃ‰NÃ‰RATION DU DASHBOARD EXCEL
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        logger.info("\n" + "â”€" * 70)
        logger.info("ğŸ“Š Ã‰TAPE 4/4 : GÃ‰NÃ‰RATION DU DASHBOARD EXCEL")
        logger.info("â”€" * 70)
        
        dashboard_file = f"{config['paths']['output_data']}/dashboard_{timestamp}.xlsx"
        create_dashboard(df_analyzed, stats, insights, dashboard_file)
        
        files_created['dashboard'] = dashboard_file
        logger.info(f"âœ… Dashboard crÃ©Ã© : {dashboard_file}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # RÃ‰SUMÃ‰ FINAL
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("\n" + "=" * 70)
        logger.info("âœ… PIPELINE TERMINÃ‰ AVEC SUCCÃˆS")
        logger.info("=" * 70)
        logger.info(f"â±ï¸  DurÃ©e totale : {duration:.2f} secondes ({duration/60:.1f} minutes)")
        logger.info(f"ğŸ“Š Nombre de produits traitÃ©s : {len(df_analyzed)}")
        logger.info(f"ğŸ’¡ Nombre d'insights gÃ©nÃ©rÃ©s : {len(insights)}")
        logger.info("")
        logger.info("ğŸ“‚ FICHIERS CRÃ‰Ã‰S :")
        logger.info(f"   â€¢ DonnÃ©es brutes      : {files_created['raw']}")
        logger.info(f"   â€¢ DonnÃ©es nettoyÃ©es   : {files_created['clean']}")
        logger.info(f"   â€¢ DonnÃ©es analysÃ©es   : {files_created['analyzed']}")
        logger.info(f"   â€¢ Dashboard Excel     : {files_created['dashboard']}")
        logger.info("=" * 70 + "\n")
        
        # Afficher un rÃ©sumÃ© des insights
        logger.info("ğŸ’¡ RÃ‰SUMÃ‰ DES INSIGHTS :")
        for i, insight in enumerate(insights, 1):
            logger.info(f"   {i}. {insight}")
        logger.info("")
        
        return True, files_created
        
    except Exception as e:
        logger.critical(f"ğŸ’¥ ERREUR CRITIQUE DANS LE PIPELINE : {e}", exc_info=True)
        return False, files_created


def print_summary(success, files_created):
    """
    Affiche un rÃ©sumÃ© visuel dans la console
    
    Args:
        success (bool): SuccÃ¨s du pipeline
        files_created (dict): Dictionnaire des fichiers crÃ©Ã©s
    """
    print("\n" + "=" * 70)
    
    if success:
        print("âœ… PIPELINE TERMINÃ‰ AVEC SUCCÃˆS")
        print("=" * 70)
        print("\nğŸ“ Fichiers gÃ©nÃ©rÃ©s :")
        
        for file_type, filepath in files_created.items():
            if filepath:
                filename = os.path.basename(filepath)
                print(f"   â€¢ {file_type.upper():12} : {filename}")
        
        print("\nğŸ¯ Prochaines Ã©tapes :")
        print("   1. Ouvrir le dashboard Excel dans data/output/")
        print("   2. Consulter les logs dÃ©taillÃ©s dans logs/")
        print("   3. Partager le dashboard avec votre Ã©quipe")
        
    else:
        print("âŒ LE PIPELINE A RENCONTRÃ‰ DES ERREURS")
        print("=" * 70)
        print("\nğŸ” Actions recommandÃ©es :")
        print("   1. Consulter les logs dans logs/")
        print("   2. VÃ©rifier la connexion rÃ©seau")
        print("   3. VÃ©rifier les fichiers de configuration")
    
    print("=" * 70 + "\n")


def main():
    """
    Point d'entrÃ©e principal
    """
    # Banner de dÃ©marrage
    print("\n" + "=" * 70)
    print("ğŸ¤– PIPELINE DE VEILLE CONCURRENTIELLE AUTOMATISÃ‰")
    print("=" * 70)
    print("Collecte â†’ Nettoyage â†’ Analyse IA â†’ Dashboard Excel")
    print("=" * 70 + "\n")
    
    # ExÃ©cuter le pipeline
    success, files_created = run_full_pipeline()
    
    # Afficher le rÃ©sumÃ©
    print_summary(success, files_created)
    
    # Code de sortie
    if success:
        logger.info("ğŸ‘ Le pipeline s'est terminÃ© sans erreur")
        sys.exit(0)  # Code de sortie 0 = succÃ¨s
    else:
        logger.error("ğŸ‘ Le pipeline a rencontrÃ© des erreurs")
        sys.exit(1)  # Code de sortie 1 = erreur


if __name__ == "__main__":
    main()